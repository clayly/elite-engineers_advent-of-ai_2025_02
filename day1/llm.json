{
  "temperature": 1.0,
  "max_tokens": 1500,
  "model": "glm-4.6",
  "streaming": false,
  "top_p": 0.9,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0
}